---
title: 'Estimating a Confidence Interval for a Proportion'
subtitle: 'Using the "Wilson Score Interval" in R'
author: "Art Eschenlauer"
date: "February 21, 2019"
output:
  pdf_document: 
    toc: yes
---


## Introductory remarks

Many ways have been developed to estimate the confidence interval for 
an observed proportion between success and trials where the probability
of success is fixed.  This document will explain **why I think that the
following  line of R code is all that you need to estimate the confidence interval**.

```
epitools::binom.wilson(x = successes, n = trials, conf.level = 0.95)
```

For lists of several methods for computing the confidence interval, see Agresti and Coull (1998) and Newcombe (1998), which are combined and summarized in the Wikipedia article, "Binomial proportion confidence interval".

Agresti and Coull (1998) recommended that elementary statistics instruction
prefer the "Score" method of Wilson (1927) for estimating the confidence
interval over the simpler, but insufficiently conservative, normal
approximation.  Wilson's formula is presented below.

I personally prefer the Wilson Score method because it performs well
for proportions that approach 0 or 1, where the normal approximation 
breaks down.
To facilitate my understanding of the Wilson Score formula, I derived it; see section
'[Derivation of Wilson's "Score Interval" formula](#derivation-of-wilsons-score-interval-formula)'.

## My test case

For my example, I will assume that 73 successes were observed for 
76 trials, and that I want a 95% confidence interval.

```{r}
successes <- 73
trials <- 76
proportion <- as.double(successes) / as.double(trials)
```

## The Wilson Score Interval - from Wilson 1927

The 1927 paper by Edwin Bidwell Wilson presented the following formula as a 
practical way to estimate the confidence interval for a proportion:

\begin{equation}
  \label{eq:1}
  \newcommand{\relmiddle}[1]{\mathrel{}\middle#1\mathrel{}}
  {
  \left. 
  p = \frac{p_0 + \frac{t}{2} \pm \sqrt{p_0q_0t + \frac{t^2}{4}}}{1 + t} 
  \relmiddle| 
  \begin{aligned}\
  \lambda &= 1.96 \text{ (for 95 percent confidence)},\\
  t &= \frac{\lambda^2}{n}, \quad
  p_0 = \frac{x}{n}, \quad
  q_0 = \frac{n - x}{n}\\
  \end{aligned}
  \right.
  }
\end{equation}

The CRAN R package `epitools` provides the `binom.wilson` function which can compute this:

```{r}
epi_wilson_ci <- 
  epitools::binom.wilson(x = successes, n = trials, conf.level = 0.95)
print(epi_wilson_ci)
```

Hoping to demystify the `epitools` implementation somewhat, I coded it directly from Wilson's equation: 

```{r}
# computational equivalent of binom.wilson from CRAN 'epitools' package
binom.wilson <-
  function(x, n, conf.level = 0.95) {
    lambda  <- qnorm(0.5*(1 + conf.level))
    # Adapted from Wilson 1927, mostly by multipling numerator
    #   and denominator by n to reduce roundoff error
    nt     <- ( lambda^2 )
    np_0   <- x
    nq_0   <- n - x
    denom   <- n + nt
    center  <- ( np_0 + nt / 2 )
    radical <- ( np_0 * nq_0 + n * (nt / 4) ) * nt / n
    delta   <- sqrt(radical)
    R.lower <- ( center - delta ) / denom
    R.upper <- ( center + delta ) / denom
    data.frame(
      x = x,
      n = n,
      proportion = as.double(np_0) / as.double(n), 
      lower = R.lower,
      upper = R.upper,
      conf.level = conf.level
    )
  }
wilson_ci <- binom.wilson(x = successes, n = trials, conf.level = 0.95)
print(wilson_ci)
```

There is negligible difference between the `epitools` implementation and my own: 

```{r}
print(wilson_ci$lower - epi_wilson_ci$lower)
print(wilson_ci$upper - epi_wilson_ci$upper)
```

I have not contrasted the two implementations to see which suffers more from round-off error, but it seems clear that they are consistent with one another.  So, having validated that the epitools implementation gives the result that I expect, I can use either one - basically, the choice is between loading another library *vs.* adding a custom function.

## A frame of reference for reasonability of the confidence interval

Does the confidence interval seem reasonable?

I manually adjusted some "guesses"" to obtain a 2.5% area under probability 
density function (PDF) curve for each tail of the binomial distribution.
Because, in actuality, this would require integration, the better choice is
to use the cumulative density function (CDF), which is the integration of the PDF.
For R, the `stats::pbinom` function implements CDF for the binomial distribution.

So, what proportion do I expect to be near the lower limit of the CI?
I expect `low.guess` to be near, *i.e.*:

```{r}
low.guess <- 0.90816
1 - pbinom(q = successes, size = trials, prob = low.guess)
```

And, I expect `high.guess` to be near the upper limit of the CI:

```{r}
high.guess <- 0.99178
1 - pbinom(q = successes, size = trials, prob = high.guess, lower.tail = FALSE)
```

How does the actual proportion behave?  I would expect the CDF for to be 50%, but it is only somewhat close:

```{r}
1 - pbinom(q = successes, size = trials, prob = proportion)
```

Increasing the number of successes and trials without changing the proportion shows that the small number of trials explains the deviation from my expectation.

```{r}
1 - pbinom(q = 100 * successes, size = 100 * trials, prob = proportion)
```

This begs the question: "If you are truly obsessed with having a 'nicely behaved' proportion, how much should you increase the number of trials?"  Here is a quick plot to address that question:

```{r}
plot(
  x = x <- c(1,2,4,8,16,32,48),
  y = y <- sapply(
    X = x, 
    FUN = function(x){
      1 - pbinom(q = x * successes, size = x * trials, prob = proportion)
    }
  ),
  xlab = "Fold increase in number of trials",
  ylab = "Area under lefthand tail",
  main = "Tuning number of trials to population proportion"
)
```

So, it looks like the point of diminishing returns would be around an eight-fold increase in the number of trials.

## Conclusions

It turns out that my reasonability guesses are pretty close to the limits of the confidence interval:

```{r}
cat(
  sprintf("For %d successes over %d trials:"
  , wilson_ci$x
  , wilson_ci$n
  ),
  sprintf("Proportion: %f"
  , wilson_ci$proportion
  ),
  sprintf("Wilson estimate of confidence interval for proportion: [%f,%f]"
  , wilson_ci$lower
  , wilson_ci$upper
  ),
  sprintf("My low and high guesses: %f,%f"
  , low.guess
  , high.guess
  ),
  sprintf("Differences from my guesses: %f, %f"
  , wilson_ci$lower - low.guess
  , wilson_ci$upper - high.guess
  ),
  sep = "\n"
)
```

I think that the results differ in part because the guesses checks are based on different actual proportions and in part because the number of trials is low.  I don't think that this casts doubt upon the confidence interval; rather, increasing the number of trials narrows the confidence interval:

```{r}
print(binom.wilson(x = 8 * successes, n = 8 * trials, conf.level = 0.95))
x <- c(1,2,4,8,16,32,48)
y.lower <- sapply(
  X = x,
  FUN = function(x){
    binom.wilson(x = x * successes, n = x * trials, conf.level = 0.95)$lower
  }
)
y.upper <- sapply(
  X = x,
  FUN = function(x){
    binom.wilson(x = x * successes, n = x * trials, conf.level = 0.95)$upper
  }
)
lbl_upper <- "Confidence Interval Upper Limit vs. Number of Trials"
lbl_lower <- "Confidence Interval Lower Limit vs. Number of Trials"
lbl_x <- "Fold-Increase in Number of Trials"
lbl_y <- "95% Confidence Interval"
plot(x = x, y = y.upper, main = lbl_upper, xlab = lbl_x, ylab = lbl_y)
plot(x = x, y = y.lower, main = lbl_lower, xlab = lbl_x, ylab = lbl_y)
```

Again, an eight-fold increase in the number of trials appears to be the point of diminishing returns.

```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

## Derivation of Wilson's "Score Interval" formula

Let $X$ be a binomally distributed random variable and let $q = 1 - p$:

\begin{equation}
X \widetilde{\,\,\,\,} B(n,p), \qquad
\overline{x} = n p, \qquad
{\sigma_x}^2 = n p (1-p) = n p q
\end{equation}

Dividing by n:

\begin{equation}
p = \frac{\overline{x}}{n}, \qquad
{\sigma_p}^2 = \frac{{\sigma_x}^2}{n^2} = \frac{p q}{n}
\end{equation}

For a 95 percent confidence interval:

\begin{equation}
\lambda = 1.96, \qquad
\text{confidence interval (score interval)} = [p - \lambda \sigma,p + \lambda \sigma]
\end{equation}

For simplicity, define t:

\begin{equation}
t = \frac{\lambda^2}{n}
\end{equation}

For $p_0$ (the observed value $p$) at either confidence limit:

\begin{equation}
(p_0 - p)^2 = \frac{\lambda^2 p q}{n} = p(1-p)t
\end{equation}

Substituting for $\lambda$:

\begin{equation}
0 = {p_0}^2 - 2 p p_0 + p^2 - pt + p^2 t
\end{equation}

Distributing $1 + t$:

\begin{equation}
0 = (1 + t)p^2 - 2(p_0 + t)p + {p_0}^2
\end{equation}

Dividing by 2:

\begin{equation}
0 = \frac{(1 + t)}{2}p^2 - (p_0 + \frac{t}{2})p + \frac{1}{2}{p_0}^2
\end{equation}

Applying the quadratic formula:

\begin{equation}
p = \frac{p_0 + \frac{t}{2} \pm \sqrt{{p_0}^2+p_0t+\frac{t^2}{4}-({p_0}^2 + {p_0}^2t)}}{1 + t}
\end{equation}

Applying $0 = {p_0}^2 - {p_0}^2$:

\begin{equation}
p = \frac{p_0 + \frac{t}{2} \pm \sqrt{p_0t+\frac{t^2}{4}-{p_0}^2t}}{1 + t}
\end{equation}

Commuting $p_0t-{p_0}^2t$: 

\begin{equation}
p = \frac{p_0 + \frac{t}{2} \pm \sqrt{p_0(1 - p_0)t+\frac{t^2}{4}}}{1 + t}
\end{equation}


## About this document

This document was produced from an RMarkdown file, the source of which should be at:

[https://eschen42.github.io/propci/propci.Rmd](https://eschen42.github.io/propci/propci.Rmd)

Revisions:

- January 23, 2019, First revision
- January 25, 2019, Added upper confidence limits plot
- February 21, 2019, Improved references

## References

Aragon, Tomas J. (2017). "epitools: Epidemiology Tools". *R package* version 0.5-10. [https://CRAN.R-project.org/package=epitools](https://CRAN.R-project.org/package=epitools)

Agresti, Alan; Coull, Brent A. (1998). "Approximate is better than 'exact' for interval estimation of binomial proportions". *The American Statistician*. 52: 119-126. [doi:10.2307/2685469](https://doi.org/10.2307/2685469).

Newcombe, Robert G.  (1998). "Two-sided confidence intervals for the single proportion: comparison of seven methods". *Statistics in Medicine* 17: 852-857. [PubMed ID: 9595616, doi:10.1002/(SICI)1097-0258(19980430)17:8<857::AID-SIM777>3.0.CO;2-E](https://www.ncbi.nlm.nih.gov/pubmed/9595616).

Wikipedia contributors, "Binomial proportion confidence interval," *Wikipedia, The Free Encyclopedia*, [https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval](https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval), accessed February 21, 2019.

Wilson, E. B. (1927). "Probable inference, the law of succession, and statistical inference". *Journal of the American Statistical Association*. 22: 209-212. [doi:10.1080/01621459.1927.10502953](https://doi.org/10.1080/01621459.1927.10502953).